{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetworkLayer(object):\n",
    "    '''\n",
    "    A Neural Network Layer\n",
    "    '''\n",
    "    def __init__(self, input_size, output_size, name=None):\n",
    "        self.number_of_neurons = output_size\n",
    "        self.inputs_per_neuron = input_size\n",
    "        self.synaptic_weights = 2 * np.random.random((input_size, output_size)) - 1\n",
    "        self.name = name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str({\n",
    "            'number_of_neurons': self.number_of_neurons, \n",
    "            'inputs_per_neuron': self.inputs_per_neuron, \n",
    "            'synaptic_weights': self.synaptic_weights, \n",
    "            'name': self.name})\n",
    "\n",
    "class MultiLayerNeuralNetwork(object):\n",
    "    '''\n",
    "    A MultiLayer Neural Network\n",
    "    '''\n",
    "    def __init__(self, layer_sizes, name=None):\n",
    "        self.layers = [ NeuralNetworkLayer(input_size, output_size, name='layer_{}'.format(i)) \n",
    "                       for (i, (input_size, output_size)) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])) ]\n",
    "        self.name = name\n",
    "\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        '''\n",
    "        Returns the outputs of all layers. Note that:\n",
    "            - Outputs of last layer is the actual prediction\n",
    "            - Outputs of the other layers are still useful (and necessary when training)\n",
    "        '''\n",
    "        layer_outputs_stack = []\n",
    "        layer_inputs = inputs # layer_inputs for first layer\n",
    "        for layer in self.layers:\n",
    "            layer_outputs = self.__sigmoid(np.dot(layer_inputs, layer.synaptic_weights))\n",
    "            layer_outputs_stack.append(layer_outputs)\n",
    "            layer_inputs = layer_outputs # layer_inputs for next layer\n",
    "        return layer_outputs_stack\n",
    "    \n",
    "    def train_step(self, training_set_inputs, training_set_outputs):\n",
    "        '''\n",
    "        Training function\n",
    "        '''\n",
    "        # Get the outputs for all layers\n",
    "        layer_outputs_stack = self.predict(training_set_inputs)\n",
    "        last_layer_outputs = layer_outputs_stack[-1]\n",
    "        # Now, for each layer, we calculate errors and backpropagate\n",
    "        reversed_layer_outputs_stack = list(reversed(layer_outputs_stack))\n",
    "        reversed_layer_inputs_stack = reversed_layer_outputs_stack[1:] + [training_set_inputs]\n",
    "        reversed_layer_stack = list(reversed(self.layers))\n",
    "        # Calculate the error for the layer in the stack\n",
    "        layer_errors = training_set_outputs - last_layer_outputs # layer_errors for last layer\n",
    "        for (layer_outputs, layer_inputs, layer) in zip(reversed_layer_outputs_stack, \n",
    "                                                        reversed_layer_inputs_stack, \n",
    "                                                        reversed_layer_stack):\n",
    "            # Calculate the deltas for this layer\n",
    "            layer_deltas = layer_errors * self.__sigmoid_derivative(layer_outputs)\n",
    "            # Calculate the weight adjustments for this layer\n",
    "            layer_adjustments = layer_inputs.T.dot(layer_deltas)\n",
    "            # Calculate the errors for the next layer in the stack \n",
    "            layer_errors = layer_deltas.dot(layer.synaptic_weights.T)\n",
    "            # Adjust the weights for this layer\n",
    "            layer.synaptic_weights += layer_adjustments\n",
    "        # Returning the prediction, so it can be used to calculate loss or accuracy at each training step\n",
    "        return last_layer_outputs\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str({'layers': self.layers, \n",
    "                    'name': self.name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [{'synaptic_weights': array([[-0.16595599,  0.44064899, -0.99977125, -0.39533485],\n",
      "       [-0.70648822, -0.81532281, -0.62747958, -0.30887855],\n",
      "       [-0.20646505,  0.07763347, -0.16161097,  0.370439  ]]), 'number_of_neurons': 4, 'inputs_per_neuron': 3, 'name': 'layer_0'}, {'synaptic_weights': array([[-0.5910955 ,  0.75623487, -0.94522481],\n",
      "       [ 0.34093502, -0.1653904 ,  0.11737966],\n",
      "       [-0.71922612, -0.60379702,  0.60148914],\n",
      "       [ 0.93652315, -0.37315164,  0.38464523]]), 'number_of_neurons': 3, 'inputs_per_neuron': 4, 'name': 'layer_1'}, {'synaptic_weights': array([[ 0.7527783 ],\n",
      "       [ 0.78921333],\n",
      "       [-0.82991158]]), 'number_of_neurons': 1, 'inputs_per_neuron': 3, 'name': 'layer_2'}], 'name': 'mlnn'}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "model = MultiLayerNeuralNetwork([3, 4, 3, 1], name='mlnn')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.24266088222915755\n",
      "mse: 0.00039285198274240405\n",
      "mse: 0.00014449637024398454\n",
      "mse: 8.63737827340187e-05\n",
      "mse: 6.1030231478078415e-05\n",
      "mse: 4.696109875877256e-05\n",
      "mse: 3.8054028963115765e-05\n",
      "mse: 3.192624864700634e-05\n",
      "mse: 2.7461233667636635e-05\n",
      "mse: 2.4067820709852033e-05\n",
      "mse: 2.140437023177554e-05\n",
      "mse: 1.9259969274216807e-05\n",
      "mse: 1.749750600631987e-05\n",
      "mse: 1.6024062329174324e-05\n",
      "mse: 1.477447889635889e-05\n",
      "mse: 1.3701734918804264e-05\n",
      "mse: 1.2771062898339076e-05\n",
      "mse: 1.1956211359611484e-05\n",
      "mse: 1.1236994477714822e-05\n",
      "mse: 1.0597640298261893e-05\n",
      "mse: 1.0025649919993934e-05\n",
      "mse: 9.51099250351692e-06\n",
      "mse: 9.045526308916226e-06\n",
      "mse: 8.62257512210963e-06\n",
      "mse: 8.236613558562766e-06\n",
      "mse: 7.883029976212709e-06\n",
      "mse: 7.557945577858168e-06\n",
      "mse: 7.258074776804811e-06\n",
      "mse: 6.980616260966469e-06\n",
      "mse: 6.723167169926439e-06\n",
      "mse: 6.483654866483043e-06\n",
      "mse: 6.260282238897176e-06\n",
      "mse: 6.051483507452444e-06\n",
      "mse: 5.855888257843095e-06\n",
      "mse: 5.672291970737802e-06\n",
      "mse: 5.499631720396973e-06\n",
      "mse: 5.336966015996307e-06\n",
      "mse: 5.183457985555446e-06\n",
      "mse: 5.0383612740523134e-06\n",
      "mse: 4.901008158680734e-06\n",
      "mse: 4.770799485458884e-06\n",
      "mse: 4.647196110078413e-06\n",
      "mse: 4.529711587375406e-06\n",
      "mse: 4.417905902231196e-06\n",
      "mse: 4.3113800730513064e-06\n",
      "mse: 4.2097714895214285e-06\n",
      "mse: 4.112749870811975e-06\n",
      "mse: 4.020013750111956e-06\n",
      "mse: 3.931287407330937e-06\n",
      "mse: 3.8463181847806025e-06\n",
      "mse: 3.764874131256518e-06\n",
      "mse: 3.6867419286436195e-06\n",
      "mse: 3.6117250623412867e-06\n",
      "mse: 3.539642202741951e-06\n",
      "mse: 3.470325769932537e-06\n",
      "mse: 3.403620657896298e-06\n",
      "mse: 3.339383097938967e-06\n",
      "mse: 3.2774796439539894e-06\n",
      "mse: 3.2177862645711603e-06\n",
      "mse: 3.1601875293032287e-06\n",
      "mse: 3.1045758775356665e-06\n",
      "mse: 3.0508509607048206e-06\n",
      "mse: 2.9989190492605195e-06\n",
      "mse: 2.9486924971024186e-06\n",
      "mse: 2.900089257101299e-06\n",
      "mse: 2.8530324421180037e-06\n",
      "mse: 2.807449926616623e-06\n",
      "mse: 2.7632739845648324e-06\n",
      "mse: 2.720440959827836e-06\n",
      "mse: 2.678890965708027e-06\n",
      "mse: 2.638567610670993e-06\n",
      "mse: 2.599417747636063e-06\n",
      "mse: 2.5613912445079773e-06\n",
      "mse: 2.524440773878558e-06\n",
      "mse: 2.4885216200595613e-06\n",
      "mse: 2.453591501805019e-06\n",
      "mse: 2.4196104092570762e-06\n",
      "mse: 2.3865404538019204e-06\n",
      "mse: 2.354345729659754e-06\n",
      "mse: 2.3229921861561762e-06\n",
      "mse: 2.292447509724722e-06\n",
      "mse: 2.2626810147888866e-06\n",
      "mse: 2.2336635427522343e-06\n",
      "mse: 2.205367368406692e-06\n",
      "mse: 2.177766113129009e-06\n",
      "mse: 2.150834664300182e-06\n",
      "mse: 2.124549100432227e-06\n",
      "mse: 2.098886621539368e-06\n",
      "mse: 2.0738254843287763e-06\n",
      "mse: 2.0493449418268637e-06\n",
      "mse: 2.0254251870907788e-06\n",
      "mse: 2.002047300688654e-06\n",
      "mse: 1.979193201655453e-06\n",
      "mse: 1.9568456016604436e-06\n",
      "mse: 1.934987962143903e-06\n",
      "mse: 1.9136044542012106e-06\n",
      "mse: 1.8926799210112033e-06\n",
      "mse: 1.8721998426218983e-06\n",
      "mse: 1.8521503029254576e-06\n",
      "mse: 1.832517958662238e-06\n",
      "Finished training!\n",
      "{'layers': [{'synaptic_weights': array([[-4.76210637,  2.02101435, -5.36550004,  0.21256025],\n",
      "       [ 1.85146871, -5.11587836, -5.41740999,  0.66871133],\n",
      "       [ 0.16057059,  0.15223796,  0.3898804 ,  0.18336739]]), 'number_of_neurons': 4, 'inputs_per_neuron': 3, 'name': 'layer_0'}, {'synaptic_weights': array([[ 1.46091007,  3.0453077 , -4.16117635],\n",
      "       [ 1.82013526,  2.5213108 , -3.64559343],\n",
      "       [-4.74204528, -5.64520067,  7.76134161],\n",
      "       [-0.77486731, -1.97629058,  2.85236261]]), 'number_of_neurons': 3, 'inputs_per_neuron': 4, 'name': 'layer_1'}, {'synaptic_weights': array([[  4.73437871],\n",
      "       [  6.78271835],\n",
      "       [-11.59000809]]), 'number_of_neurons': 1, 'inputs_per_neuron': 3, 'name': 'layer_2'}], 'name': 'mlnn'}\n"
     ]
    }
   ],
   "source": [
    "# The training set. We have 7 examples, each consisting of 3 input values and 1 output value\n",
    "training_set_inputs = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
    "training_set_outputs = np.array([[0, 1, 1, 1, 1, 0, 0]]).T\n",
    "# Train the neural network using the training set\n",
    "for iteration in range(100000):\n",
    "    pred_outputs = model.train_step(training_set_inputs, training_set_outputs)\n",
    "    if(iteration % 1000 == 0):\n",
    "        errors = training_set_outputs - pred_outputs\n",
    "        mse = (errors ** 2).mean()\n",
    "        print('mse: {}'.format(mse))\n",
    "print('Finished training!')\n",
    "# Model after training:\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.33120340e-04]\n",
      " [  9.98677044e-01]\n",
      " [  9.98688527e-01]\n",
      " [  9.98841625e-01]\n",
      " [  9.98953427e-01]\n",
      " [  1.90535554e-03]\n",
      " [  1.74481021e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Just checking how it adjusts to the training set\n",
    "layer_outputs_stack = model.predict(training_set_inputs)\n",
    "print(layer_outputs_stack[len(layer_outputs_stack) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00212492]]\n"
     ]
    }
   ],
   "source": [
    "# Test the neural network with a new input -> ?:\n",
    "test_set_inputs = np.array([[1, 1, 0]])\n",
    "layer_outputs_stack = model.predict(test_set_inputs)\n",
    "print(layer_outputs_stack[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
